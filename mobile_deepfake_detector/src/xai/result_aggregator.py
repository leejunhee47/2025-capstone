import uuid
from datetime import datetime
from typing import Dict, Any
import logging

# Setup logger
logger = logging.getLogger(__name__)

class ResultAggregator:
    """
    Result Aggregator for combining insights and generating final results.
    
    Simplified for Unified Hybrid Pipeline:
    - Ensembles MMMS-BA and PIA results
    - Generates Korean summaries based on overall analysis
    """

    def __init__(self):
        logger.info("Initializing ResultAggregator...")

    def ensemble(
        self,
        mmms_result: Dict[str, Any],
        pia_result: Dict[str, Any],
        weights: Dict[str, float] = {'mmms': 0.7, 'pia': 0.3}
    ) -> Dict[str, Any]:
        """
        Ensemble MMMS-BA and PIA results.
        
        Args:
            mmms_result: Output from Stage1Scanner.predict_full_video
            pia_result: Output from Stage2Analyzer.predict_full_video
            weights: Weights for ensemble (default: 0.4 for MMMS-BA, 0.6 for PIA)
            
        Returns:
            final_result: Combined detection result
        """
        # Extract probabilities (fake prob)
        mmms_prob = mmms_result.get('probabilities', {}).get('fake', 0.0)
        
        # PIA result structure (from explainer)
        if 'detection' in pia_result:
            pia_prob = pia_result['detection'].get('probabilities', {}).get('fake', 0.0)
        else:
            # Fallback or if PIA failed
            pia_prob = pia_result.get('probabilities', {}).get('fake', 0.0)
            if pia_prob == 0.0 and pia_result.get('verdict') == 'unknown':
                # If PIA failed, rely on MMMS-BA
                weights = {'mmms': 1.0, 'pia': 0.0}
                logger.warning("PIA result unknown, falling back to MMMS-BA only.")
            
        # Weighted ensemble
        w_mmms = weights['mmms']
        w_pia = weights['pia']
        
        # [NEW] Conservative Ensemble Logic: If any model is highly confident (>0.9) about FAKE,
        # prioritize that signal. This prevents one model's failure from masking a strong detection.
        STRONG_THRESHOLD = 0.90

        if mmms_prob > STRONG_THRESHOLD:
            logger.info(f"Strong FAKE signal from MMMS-BA ({mmms_prob:.4f}). Prioritizing MMMS-BA.")
            final_prob = mmms_prob
            w_mmms, w_pia = 1.0, 0.0

        elif pia_prob > STRONG_THRESHOLD:
            logger.info(f"Strong FAKE signal from PIA ({pia_prob:.4f}). Prioritizing PIA.")
            final_prob = pia_prob
            w_mmms, w_pia = 0.0, 1.0

        else:
            # Standard weighted average for ambiguous cases
            total_w = w_mmms + w_pia
            if total_w > 0:
                w_mmms /= total_w
                w_pia /= total_w

            final_prob = w_mmms * mmms_prob + w_pia * pia_prob
        
        verdict = 'fake' if final_prob > 0.5 else 'real'
        confidence = final_prob if verdict == 'fake' else 1.0 - final_prob

        # ê°œë³„ ëª¨ë¸ íŒì • ë° ì‹ ë¢°ë„ ê³„ì‚°
        mmms_verdict = 'fake' if mmms_prob > 0.5 else 'real'
        mmms_confidence = mmms_prob if mmms_verdict == 'fake' else 1.0 - mmms_prob

        pia_verdict = 'fake' if pia_prob > 0.5 else 'real'
        pia_confidence = pia_prob if pia_verdict == 'fake' else 1.0 - pia_prob

        return {
            'verdict': verdict,
            'confidence': float(confidence),
            'probabilities': {
                'real': 1.0 - final_prob,
                'fake': float(final_prob)
            },
            'details': {
                # MMMS-BA ê°œë³„ ê²°ê³¼
                'mmms_verdict': mmms_verdict,
                'mmms_confidence': float(mmms_confidence),
                'mmms_fake_prob': float(mmms_prob),
                # PIA ê°œë³„ ê²°ê³¼
                'pia_verdict': pia_verdict,
                'pia_confidence': float(pia_confidence),
                'pia_fake_prob': float(pia_prob),
                # ì•™ìƒë¸” ê°€ì¤‘ì¹˜
                'weights': {'mmms': w_mmms, 'pia': w_pia}
            }
        }

    def generate_korean_summary(
        self,
        detection: Dict[str, Any],
        pia_result: Dict[str, Any],
        video_info: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        Generate user-friendly Korean summary based on ensemble result.
        """
        confidence = detection['confidence']
        verdict = detection['verdict']
        
        # Risk level
        risk_level = self._compute_risk_level(confidence, verdict)
        
        # Title
        if verdict == 'fake':
            title = f"âš ï¸ ë”¥í˜ì´í¬ ì˜ìƒ ì˜ì‹¬ë¨ (ì‹ ë¢°ë„: {confidence*100:.1f}%)"
        else:
            title = f"âœ… ì§„ì§œ ì˜ìƒìœ¼ë¡œ íŒì • (ì‹ ë¢°ë„: {confidence*100:.1f}%)"
            
        # Primary Reason with MAR Deviation (ìš°ì„ ìˆœìœ„ 1) ë˜ëŠ” interval info
        primary_reason = ""
        if verdict == 'fake':
            # [ìš°ì„ ìˆœìœ„ 1] MAR Deviation ê¸°ë°˜ ì„¤ëª… (ê°€ì¥ í•´ì„ ê°€ëŠ¥)
            geometry_analysis = pia_result.get('geometry_analysis', {})
            abnormal_phonemes = geometry_analysis.get('abnormal_phonemes', [])
            
            if abnormal_phonemes:
                # ê°€ì¥ ì‹¬ê°í•œ ì´ìƒ phoneme ì„ íƒ (z-score ê¸°ì¤€)
                worst = max(abnormal_phonemes, key=lambda x: abs(x.get('z_score', 0)))
                
                # í¸ì°¨ í¼ì„¼íŠ¸ ê³„ì‚°
                expected_mean = worst.get('expected_mean', 0.3)
                if expected_mean > 0:
                    deviation_pct = abs(worst['deviation'] / expected_mean * 100)
                else:
                    deviation_pct = abs(worst['deviation']) * 100
                
                # ë°©í–¥ ê²°ì •
                direction = "ë” í¬ê²Œ" if worst['deviation'] > 0 else "ë” ì‘ê²Œ"
                
                # êµ¬ê°„ ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨
                if 'best_interval' in pia_result:
                    interval = pia_result['best_interval']
                    primary_reason = (
                        f"{interval['start']:.1f}~{interval['end']:.1f}ì´ˆ êµ¬ê°„ì—ì„œ "
                        f"'{worst['phoneme']}' ë°œìŒ ì‹œ ì…ì„ {deviation_pct:.0f}% {direction} ë²Œë ¤ "
                        f"ë¶€ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤."
                    )
                else:
                    primary_reason = (
                        f"'{worst['phoneme']}' ë°œìŒ ì‹œ ì…ì„ {deviation_pct:.0f}% {direction} ë²Œë ¤ "
                        f"ë¶€ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤."
                    )
            
            # [ìš°ì„ ìˆœìœ„ 2] Interval info (MAR deviation ì—†ì„ ë•Œ)
            elif 'best_interval' in pia_result:
                interval = pia_result['best_interval']
                # Filter out <pad> tokens before selecting top phonemes
                all_phonemes = pia_result.get('matched_phonemes', [])
                valid_phonemes = [p for p in all_phonemes if p and p != '<pad>'][:3]

                # [HYBRID] Convert MFA codes to Korean characters for UX
                from ..utils.korean_phoneme_config import phoneme_to_korean
                korean_phonemes = [phoneme_to_korean(p) for p in valid_phonemes]
                phoneme_str = ', '.join(f"/{p}/" for p in korean_phonemes) if korean_phonemes else "ì—¬ëŸ¬ ë°œìŒ"

                primary_reason = (
                    f"{interval['start']:.1f}~{interval['end']:.1f}ì´ˆ êµ¬ê°„ì—ì„œ "
                    f"{phoneme_str} ë“±ì˜ ë°œìŒ ì‹œ ì…ëª¨ì–‘ ë¶ˆì¼ì¹˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."
                )
            # [ìš°ì„ ìˆœìœ„ 3] Original PIA insights (Attention ê¸°ë°˜)
            elif 'phoneme_analysis' in pia_result:
                top_phonemes = pia_result['phoneme_analysis'].get('top_suspicious_phonemes', [])
                if top_phonemes:
                    primary_reason = f"'{top_phonemes[0]['phoneme']}' ë°œìŒ ì‹œ ì…ëª¨ì–‘ ë¶€ìì—°ìŠ¤ëŸ¬ì›€ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."
                else:
                    primary_reason = "ì˜ìƒ ì „ë°˜ì— ê±¸ì³ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ì… ì›€ì§ì„ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."
            else:
                primary_reason = "ë”¥í˜ì´í¬ íƒì§€ ëª¨ë¸ì´ ì˜ìƒ ì¡°ì‘ í”ì ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤."
        else:
            primary_reason = "ë¶„ì„ ê²°ê³¼, ë”¥í˜ì´í¬ë¡œ ì˜ì‹¬ë˜ëŠ” íŠ¹ì§•ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
        # Detailed Explanation
        detailed_explanation = self._build_detailed_explanation(detection, pia_result)
        
        # Detail View (Mobile)
        detail_view = self._build_detail_view(detection, pia_result, video_info)
        
        return {
            'title': title,
            'risk_level': risk_level,
            'primary_reason': primary_reason,
            'detailed_explanation': detailed_explanation,
            'detail_view': detail_view
        }

    def _compute_risk_level(self, confidence: float, verdict: str) -> str:
        if verdict == 'fake':
            if confidence > 0.85: return 'critical'
            elif confidence > 0.7: return 'high'
            elif confidence > 0.5: return 'medium'
            else: return 'low'
        else:
            # For real verdict, high confidence means low risk
            if confidence > 0.8: return 'low'
            elif confidence > 0.6: return 'medium'
            else: return 'high' # Uncertain real

    def _build_detailed_explanation(self, detection: Dict, pia_result: Dict) -> str:
        verdict = detection['verdict']
        details = detection['details']

        if verdict == 'fake':
            parts = [f"ì¢…í•© ë¶„ì„ ê²°ê³¼ {detection['confidence']*100:.1f}% í™•ë¥ ë¡œ ë”¥í˜ì´í¬ì…ë‹ˆë‹¤."]

            # [ìš°ì„ ìˆœìœ„ 1] MAR Deviation ìƒì„¸ ì„¤ëª…
            geometry_analysis = pia_result.get('geometry_analysis', {})
            abnormal_phonemes = geometry_analysis.get('abnormal_phonemes', [])
            
            if abnormal_phonemes:
                # ê°€ì¥ ì‹¬ê°í•œ ì´ìƒ phonemeë“¤ ì„¤ëª…
                sorted_abnormal = sorted(
                    abnormal_phonemes,
                    key=lambda x: abs(x.get('z_score', 0)),
                    reverse=True
                )
                
                top_abnormal = sorted_abnormal[:2]  # Top 2
                phoneme_descriptions = []
                
                for abnormal in top_abnormal:
                    phoneme = abnormal['phoneme']
                    deviation = abnormal.get('deviation', 0)
                    expected_mean = abnormal.get('expected_mean', 0.3)
                    z_score = abnormal.get('z_score', 0)
                    
                    if expected_mean > 0:
                        deviation_pct = abs(deviation / expected_mean * 100)
                    else:
                        deviation_pct = abs(deviation) * 100
                    
                    direction = "ë” í¬ê²Œ" if deviation > 0 else "ë” ì‘ê²Œ"
                    phoneme_descriptions.append(
                        f"'{phoneme}' ë°œìŒ ì‹œ ì…ì„ {deviation_pct:.0f}% {direction} ë²Œë¦¼"
                    )
                
                if phoneme_descriptions:
                    parts.append(f"ì…ëª¨ì–‘ ë¶„ì„ ê²°ê³¼: {', '.join(phoneme_descriptions)}.")
                
                # êµ¬ê°„ ì •ë³´ ì¶”ê°€
                if 'best_interval' in pia_result:
                    interval = pia_result['best_interval']
                    parts.append(
                        f"ì´ìƒ íŒ¨í„´ì€ {interval['start']:.1f}~{interval['end']:.1f}ì´ˆ êµ¬ê°„ì—ì„œ "
                        f"íŠ¹íˆ ë‘ë“œëŸ¬ì§‘ë‹ˆë‹¤."
                    )

            # [ìš°ì„ ìˆœìœ„ 2] Interval info (MAR deviation ì—†ì„ ë•Œ)
            elif 'best_interval' in pia_result:
                interval = pia_result['best_interval']
                parts.append(
                    f"PIA ëª¨ë¸ì´ {interval['start']:.1f}~{interval['end']:.1f}ì´ˆ êµ¬ê°„ì—ì„œ "
                    f"ì…ëª¨ì–‘ ë¶ˆì¼ì¹˜ë¥¼ íƒì§€í–ˆìŠµë‹ˆë‹¤."
                )

                # Multiple intervals
                if pia_result.get('num_intervals_analyzed', 0) > 1:
                    parts.append(
                        f"(ì´ {pia_result['num_intervals_analyzed']}ê°œì˜ ì˜ì‹¬ êµ¬ê°„ ë¶„ì„)"
                    )

            # [ìš°ì„ ìˆœìœ„ 3] Original branch contribution
            elif 'branch_contributions' in pia_result:
                bc = pia_result.get('branch_contributions', {})
                top_branch = bc.get('top_branch', 'unknown')
                if top_branch != 'unknown':
                    parts.append(f"íŠ¹íˆ {top_branch} íŠ¹ì§•ì—ì„œ ì¡°ì‘ í”ì ì´ ë‘ë“œëŸ¬ì§‘ë‹ˆë‹¤.")

            return " ".join(parts)
        else:
            return f"MMMS-BAì™€ PIA ëª¨ë¸ ëª¨ë‘ ì •ìƒ ë²”ì£¼ ë‚´ì˜ íŒ¨í„´ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. (MMMS: {details['mmms_fake_prob']:.2f}, PIA: {details['pia_fake_prob']:.2f})"

    def _build_detail_view(self, detection: Dict, pia_result: Dict, video_info: Dict) -> Dict:
        """Build mobile app view data"""
        
        key_findings = []
        
        if detection['verdict'] == 'fake':
            # [ìš°ì„ ìˆœìœ„ 1] MAR Deviation ê¸°ë°˜ ë°œê²¬ì‚¬í•­ (ê°€ì¥ í•´ì„ ê°€ëŠ¥)
            geometry_analysis = pia_result.get('geometry_analysis', {})
            abnormal_phonemes = geometry_analysis.get('abnormal_phonemes', [])
            
            if abnormal_phonemes:
                # ì‹¬ê°ë„ ìˆœìœ¼ë¡œ ì •ë ¬ (z-score ê¸°ì¤€)
                sorted_abnormal = sorted(
                    abnormal_phonemes, 
                    key=lambda x: abs(x.get('z_score', 0)), 
                    reverse=True
                )
                
                for abnormal in sorted_abnormal[:3]:  # Top 3
                    z_score = abs(abnormal.get('z_score', 0))
                    deviation = abnormal.get('deviation', 0)
                    expected_mean = abnormal.get('expected_mean', 0.3)
                    
                    # í¸ì°¨ í¼ì„¼íŠ¸ ê³„ì‚°
                    if expected_mean > 0:
                        deviation_pct = abs(deviation / expected_mean * 100)
                    else:
                        deviation_pct = abs(deviation) * 100
                    
                    # ë°©í–¥ ê²°ì •
                    direction = "ë” í¬ê²Œ" if deviation > 0 else "ë” ì‘ê²Œ"
                    
                    # ì‹¬ê°ë„ ê²°ì •
                    if z_score > 3:
                        severity = 'critical'
                        icon = 'ğŸ”´'
                    elif z_score > 2:
                        severity = 'high'
                        icon = 'ğŸŸ '
                    else:
                        severity = 'medium'
                        icon = 'ğŸŸ¡'
                    
                    key_findings.append({
                        'type': 'mar_deviation',
                        'icon': icon,
                        'title': f"'{abnormal['phoneme']}' ë°œìŒ ì´ìƒ",
                        'description': f"ì…ì„ {deviation_pct:.0f}% {direction} ë²Œë¦¼ (Z-score: {z_score:.1f})",
                        'severity': severity,
                        'phoneme': abnormal['phoneme'],
                        'measured_mar': abnormal.get('measured_mar', 0.0),
                        'expected_range': abnormal.get('expected_range', [0.0, 0.0]),
                        'z_score': z_score
                    })
            
            # [ìš°ì„ ìˆœìœ„ 2] Attention ê¸°ë°˜ ë°œê²¬ì‚¬í•­ (MAR deviation ì—†ì„ ë•Œë§Œ)
            if not abnormal_phonemes and 'phoneme_analysis' in pia_result:
                pa = pia_result['phoneme_analysis']
                for p_score in pa.get('phoneme_scores', [])[:2]: # Top 2
                    if p_score.get('is_suspicious'):
                        key_findings.append({
                            'type': 'phoneme_attention',
                            'icon': 'ğŸ—£ï¸',
                            'title': f"ë°œìŒ '{p_score['phoneme_korean']}' ì£¼ëª©",
                            'description': f"ëª¨ë¸ì´ ì´ ìŒì†Œì— ì§‘ì¤‘í•¨ (ì–´í…ì…˜: {p_score['attention_weight']*100:.1f}%)",
                            'severity': 'medium',
                            'note': 'ì£¼ì˜: ì–´í…ì…˜ì´ ë†’ë‹¤ê³  ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤'
                        })
                        
        return {
            'key_findings': key_findings,
            'model_results': {
                # MMMS-BA ê°œë³„ ê²°ê³¼
                'mmms_verdict': detection['details']['mmms_verdict'],
                'mmms_confidence': detection['details']['mmms_confidence'],
                'mmms_fake_prob': detection['details']['mmms_fake_prob'],
                # PIA ê°œë³„ ê²°ê³¼
                'pia_verdict': detection['details']['pia_verdict'],
                'pia_confidence': detection['details']['pia_confidence'],
                'pia_fake_prob': detection['details']['pia_fake_prob'],
                # ì•™ìƒë¸” ê²°ê³¼
                'ensemble_verdict': detection['verdict'],
                'ensemble_confidence': detection['confidence']
            },
            'video_info': video_info or {}
        }

    def extract_video_info(self, video_path: str) -> Dict[str, Any]:
        import cv2
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        duration_sec = total_frames / fps if fps > 0 else 0.0
        cap.release()

        return {
            'duration_sec': float(duration_sec),
            'total_frames': total_frames,
            'fps': float(fps),
            'resolution': f"{width}x{height}",
            'original_path': str(video_path)
        }

    def build_final_result(
        self,
        video_path: str,
        video_id: str,
        detection: Dict[str, Any],
        summary: Dict[str, Any],
        video_info: Dict[str, Any],
        processing_time_ms: float,
        suspicious_intervals: list = None
    ) -> Dict[str, Any]:
        """
        ìµœì¢… ê²°ê³¼ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.

        Args:
            video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            video_id: ë¹„ë””ì˜¤ ID
            detection: íƒì§€ ê²°ê³¼
            summary: í•œêµ­ì–´ ìš”ì•½
            video_info: ë¹„ë””ì˜¤ ì •ë³´
            processing_time_ms: ì²˜ë¦¬ ì‹œê°„ (ë°€ë¦¬ì´ˆ)
            suspicious_intervals: ì˜ì‹¬ êµ¬ê°„ ë¦¬ìŠ¤íŠ¸

        Returns:
            ìµœì¢… ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        request_id = f"req_{uuid.uuid4().hex[:8]}"

        # ì˜ì‹¬ êµ¬ê°„ í”„ë ˆì„ ê°œìˆ˜ ì¶”ê°€
        suspicious_frame_count = 0
        if suspicious_intervals and len(suspicious_intervals) > 0:
            suspicious_frame_count = suspicious_intervals[0].get('frame_count', 0)

        return {
            'metadata': {
                'video_id': video_id,
                'request_id': request_id,
                'processed_at': datetime.utcnow().isoformat() + 'Z',
                'processing_time_ms': processing_time_ms,
                'pipeline_version': 'unified_v2.0'
            },
            'video_info': video_info,
            'detection': detection,
            'summary': summary,
            'suspicious_frame_count': suspicious_frame_count
        }
