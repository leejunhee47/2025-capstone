# PIA Model Training Configuration
# Phase 1: Baseline training with dummy ArcFace

# Data settings
data:
  data_dir: preprocessed_data_phoneme/
  num_phonemes: 14  # Korean phoneme vocabulary
  frames_per_phoneme: 5  # Frames per phoneme class
  image_size: 112  # Lip crop size (112x112)

# Model architecture
model:
  arcface_dim: 512  # ArcFace embedding dimension
  geo_dim: 1  # Geometry features (MAR only)
  embed_dim: 128  # Hidden embedding dimension
  num_heads: 4  # Multi-head attention heads
  num_classes: 2  # Binary classification (Real/Fake)
  use_temporal_loss: false  # Phase 1: No temporal consistency loss

# Training settings
training:
  epochs: 30
  batch_size: 8  # Adjust based on GPU memory
  learning_rate: 0.0001
  weight_decay: 0.0001

  # Optimizer
  optimizer: adam
  scheduler: reduce_lr_on_plateau
  scheduler_patience: 5
  scheduler_factor: 0.5

  # Early stopping
  early_stopping_patience: 10

  # Mixed precision (optional, for faster training)
  mixed_precision: false

# DataLoader settings
dataloader:
  num_workers: 0  # Windows: use 0, Linux: 4
  pin_memory: true
  shuffle: true

# Output paths
output:
  checkpoint_dir: outputs/pia_baseline/checkpoints/
  log_dir: outputs/pia_baseline/logs/
  tensorboard_dir: outputs/pia_baseline/tensorboard/

# Device
device: cuda  # or 'cpu'

# Logging
logging:
  log_every_n_steps: 10
  save_every_n_epochs: 5
