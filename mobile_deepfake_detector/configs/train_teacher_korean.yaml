# Teacher Model Training Configuration (Korean Dataset)
# MMMS-BA (Multi-Modal Multi-Sequence Bi-Modal Attention)

experiment:
  name: "teacher_mmms_ba_korean_v1"
  seed: 42
  device: "cuda"  # cuda | cpu
  num_gpus: 1

# Model Architecture
model:
  name: "MMMS_BA"

  # GRU Configuration
  gru:
    hidden_size: 300  # Bi-directional: 300*2 = 600
    num_layers: 1
    dropout: 0.5
    recurrent_dropout: 0.5
    bidirectional: true

  # Dense Layer
  dense:
    hidden_size: 100
    dropout: 0.7
    activation: "tanh"

  # Attention
  attention:
    type: "bi_modal"  # bi_modal | self | none
    num_heads: 12

  # Output
  num_classes: 2  # Real, Fake

# Dataset
dataset:
  name: "Korean_Deepfake"
  root_dir: "E:/capstone/preprocessed_data_real"  # 실제 한국어 데이터셋 (975개)

  # Modalities
  modalities:
    - audio
    - visual
    - lip

  # Video Settings (Shorts optimized)
  video:
    max_duration: 60  # seconds
    min_duration: 10  # 한국어 데이터셋은 더 짧을 수 있음
    target_fps: 30
    max_frames: 50
    frame_size: [224, 224]

  # Audio Settings
  audio:
    sample_rate: 16000
    n_mfcc: 40
    hop_length: 512
    n_fft: 2048

  # Lip Region
  lip:
    size: [96, 96]
    detector: "haar_cascade"  # haar_cascade | dlib

  # Split
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15

  # Data Augmentation (경량화)
  augmentation:
    enabled: true

    # Video augmentation
    video_aug:
      - type: "compression"
        params:
          codecs: ["h264"]
          crf: [23, 28]
          prob: 0.3

      - type: "noise"
        params:
          std: [0.01, 0.03]
          prob: 0.2

      - type: "color_jitter"
        params:
          brightness: 0.1
          contrast: 0.1
          saturation: 0.1
          hue: 0.05
          prob: 0.3

    # Audio augmentation
    audio_aug:
      - type: "noise"
        params:
          snr_db: [15, 25]
          prob: 0.2

# Training
training:
  # Optimizer
  optimizer:
    type: "adam"
    lr: 0.0005  # 한국어 데이터셋이 작으므로 낮은 학습률
    betas: [0.9, 0.999]
    weight_decay: 0.0001

  # Scheduler
  scheduler:
    type: "cosine"
    T_max: 15  # 15 에폭에 맞춤
    eta_min: 0.00001

  # Loss
  loss:
    type: "cross_entropy"
    label_smoothing: 0.1

  # Training Settings
  epochs: 15  # 테스트용 (원래: 15)
  batch_size: 2  # 메모리 안전을 위해 최소화
  num_workers: 0  # Windows 메모리 에러 방지

  # ⚡ 병렬 학습 최적화
  use_prefetch: false  # 메모리 안정성 우선
  gradient_accumulation_steps: 4  # Effective batch size: 8 유지
  use_compile: false  # 메모리 절약

  # Gradient Clipping
  grad_clip:
    enabled: true
    max_norm: 1.0

  # Mixed Precision (FP16)
  mixed_precision: true

  # Checkpointing
  checkpoint:
    save_best: true
    save_last: true
    monitor: "val_acc"
    mode: "max"
    save_dir: "models/checkpoints/korean"

  # Early Stopping
  early_stopping:
    enabled: true
    patience: 5  # epoch 15이므로 여유 필요
    monitor: "val_loss"
    mode: "min"

  # Class Imbalance Handling
  use_weighted_sampler: true  # WeightedRandomSampler 사용
  use_weighted_loss: true     # Weighted CrossEntropyLoss 사용
  class_weights: [5.0, 1.0]   # [Real, Fake] - Real에 5배 가중치

  # Logging
  logging:
    interval: 5  # steps
    wandb:
      enabled: false
      project: "mobile_deepfake_detector"
      entity: "your_username"

# Validation
validation:
  interval: 1  # epochs
  batch_size: 16

# Metrics
metrics:
  - accuracy
  - precision
  - recall
  - f1_score
  - auc

# Paths
paths:
  data_dir: "E:/capstone/preprocessed_data_real"
  model_dir: "models"
  log_dir: "logs/korean"
  output_dir: "outputs/korean"

