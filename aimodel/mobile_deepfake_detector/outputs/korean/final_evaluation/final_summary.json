{
  "experiment": "Mobile Deepfake Detector - Final Evaluation",
  "model": "MMMS-BA (Improved)",
  "parameters": "3.04M",
  "training_time_minutes": 40,
  "dataset": {
    "name": "Korean Deepfake Dataset",
    "train_samples": 595,
    "val_samples": 133,
    "test_samples": 131,
    "imbalance_ratio": "1:4.7 (Real:Fake)"
  },
  "test_performance": {
    "accuracy": 0.9770992366412213,
    "precision": 0.981651376146789,
    "recall": 0.9907407407407407,
    "f1_score": 0.9861751152073732,
    "auc": 0.996779388083736,
    "confusion_matrix": [
      [
        21,
        2
      ],
      [
        1,
        107
      ]
    ],
    "true_negatives": 21,
    "false_positives": 2,
    "false_negatives": 1,
    "true_positives": 107,
    "error_rate": 0.022900763358778664
  },
  "comparison": {
    "baseline": {
      "train_acc": 0.9579,
      "val_acc": 0.9474,
      "test_acc": 0.9771
    },
    "improved": {
      "train_acc": 0.8924,
      "val_acc": 0.9925,
      "test_acc": 0.9770992366412213
    },
    "improvements": {
      "val_acc_gain": 0.04510000000000003,
      "val_acc_gain_percent": 4.760396875659703,
      "overfitting_resolved": true
    }
  },
  "generalization": {
    "train_val_gap": -0.10010000000000008,
    "val_test_gap": 0.015400763358778713,
    "train_test_gap": -0.08469923664122136,
    "analysis": "Excellent generalization: Val > Train, indicating robust learning"
  },
  "techniques_applied": [
    "Data Augmentation (Audio + Visual + Lip)",
    "Weighted Random Sampler",
    "Weighted Cross-Entropy Loss",
    "Dropout (0.5, 0.7)",
    "Weight Decay (0.0001)",
    "Early Stopping (patience=5)",
    "Mixed Precision Training",
    "Gradient Accumulation (x4)"
  ],
  "deployment_ready": true,
  "next_steps": [
    "Model compression (Pruning + Quantization)",
    "Knowledge distillation to Student model",
    "TFLite conversion for mobile",
    "Production API deployment",
    "Real-time inference optimization"
  ]
}